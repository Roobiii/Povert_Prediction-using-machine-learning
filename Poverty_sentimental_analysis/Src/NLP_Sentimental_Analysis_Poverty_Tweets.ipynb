{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Natural Language processing and Sentimental Analysis of Poverty Tweets\n",
    "Author : Prajakta Gaydhani "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import string\n",
    "import nltk\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Read Cleaned Poverty Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"CleanedPovertyTweets_v1.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Convert all tweets to Lower Case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     growing food and faith in impoverished brazil...\n",
       "1     in yrs vietnam from poverty to an emerging ma...\n",
       "2     the politics of poverty officials grapple wit...\n",
       "3     not just talking doing kenyalendahand kenya n...\n",
       "4                                     raiders poverty \n",
       "5     for all those who believe the world has gone ...\n",
       "6     even breathing is a risk in one of orlando s ...\n",
       "7     maybe it s time to rethink the idea that we k...\n",
       "8     this is why i volunteer with big bros big sis...\n",
       "9     americas children in brief key national indic...\n",
       "Name: Tweets, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['Tweets'] = train['Tweets'].apply(lambda x: x.lower())\n",
    "train.Tweets.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Stop Words Removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop = stopwords.words('english')\n",
    "train['Tweets'] = train['Tweets'].apply(lambda x: \" \".join(x for x in x.split() if x not in stop))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Date</th>\n",
       "      <th>Tweets</th>\n",
       "      <th>uncleaned_len</th>\n",
       "      <th>cleaned_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2018-09-30 19:39</td>\n",
       "      <td>growing food faith impoverished brazil ben dem...</td>\n",
       "      <td>247</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2018-09-30 19:37</td>\n",
       "      <td>yrs vietnam poverty emerging market ans oi moi...</td>\n",
       "      <td>429</td>\n",
       "      <td>220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2018-09-30 19:37</td>\n",
       "      <td>politics poverty officials grapple works doesn...</td>\n",
       "      <td>309</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2018-09-30 19:29</td>\n",
       "      <td>talking kenyalendahand kenya nairobi kibera ja...</td>\n",
       "      <td>292</td>\n",
       "      <td>166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2018-09-30 19:24</td>\n",
       "      <td>raiders poverty</td>\n",
       "      <td>25</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0              Date  \\\n",
       "0           1  2018-09-30 19:39   \n",
       "1           2  2018-09-30 19:37   \n",
       "2           3  2018-09-30 19:37   \n",
       "3           4  2018-09-30 19:29   \n",
       "4           5  2018-09-30 19:24   \n",
       "\n",
       "                                              Tweets  uncleaned_len  \\\n",
       "0  growing food faith impoverished brazil ben dem...            247   \n",
       "1  yrs vietnam poverty emerging market ans oi moi...            429   \n",
       "2  politics poverty officials grapple works doesn...            309   \n",
       "3  talking kenyalendahand kenya nairobi kibera ja...            292   \n",
       "4                                    raiders poverty             25   \n",
       "\n",
       "   cleaned_len  \n",
       "0           89  \n",
       "1          220  \n",
       "2           96  \n",
       "3          166  \n",
       "4           17  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 Spell Correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.Tweets.apply(lambda x: TextBlob(x).correct);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 Tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "train['Tokensize']= train.Tweets.apply(lambda x: word_tokenize(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Date</th>\n",
       "      <th>Tweets</th>\n",
       "      <th>uncleaned_len</th>\n",
       "      <th>cleaned_len</th>\n",
       "      <th>Tokensize</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2018-09-30 19:39</td>\n",
       "      <td>growing food faith impoverished brazil ben dem...</td>\n",
       "      <td>247</td>\n",
       "      <td>89</td>\n",
       "      <td>[growing, food, faith, impoverished, brazil, b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2018-09-30 19:37</td>\n",
       "      <td>yrs vietnam poverty emerging market ans oi moi...</td>\n",
       "      <td>429</td>\n",
       "      <td>220</td>\n",
       "      <td>[yrs, vietnam, poverty, emerging, market, ans,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2018-09-30 19:37</td>\n",
       "      <td>politics poverty officials grapple works doesn...</td>\n",
       "      <td>309</td>\n",
       "      <td>96</td>\n",
       "      <td>[politics, poverty, officials, grapple, works,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2018-09-30 19:29</td>\n",
       "      <td>talking kenyalendahand kenya nairobi kibera ja...</td>\n",
       "      <td>292</td>\n",
       "      <td>166</td>\n",
       "      <td>[talking, kenyalendahand, kenya, nairobi, kibe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2018-09-30 19:24</td>\n",
       "      <td>raiders poverty</td>\n",
       "      <td>25</td>\n",
       "      <td>17</td>\n",
       "      <td>[raiders, poverty]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>2018-09-30 19:23</td>\n",
       "      <td>believe world gone bonkers need evolve better ...</td>\n",
       "      <td>234</td>\n",
       "      <td>212</td>\n",
       "      <td>[believe, world, gone, bonkers, need, evolve, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>2018-09-30 19:13</td>\n",
       "      <td>even breathing risk one orlando poorest neighb...</td>\n",
       "      <td>207</td>\n",
       "      <td>151</td>\n",
       "      <td>[even, breathing, risk, one, orlando, poorest,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>2018-09-30 19:09</td>\n",
       "      <td>maybe time rethink idea know better people nee...</td>\n",
       "      <td>192</td>\n",
       "      <td>125</td>\n",
       "      <td>[maybe, time, rethink, idea, know, better, peo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>2018-09-30 19:00</td>\n",
       "      <td>volunteer big bros big sisters many american k...</td>\n",
       "      <td>191</td>\n",
       "      <td>166</td>\n",
       "      <td>[volunteer, big, bros, big, sisters, many, ame...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>2018-09-30 19:00</td>\n",
       "      <td>americas children brief key national indicator...</td>\n",
       "      <td>279</td>\n",
       "      <td>211</td>\n",
       "      <td>[americas, children, brief, key, national, ind...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0              Date  \\\n",
       "0           1  2018-09-30 19:39   \n",
       "1           2  2018-09-30 19:37   \n",
       "2           3  2018-09-30 19:37   \n",
       "3           4  2018-09-30 19:29   \n",
       "4           5  2018-09-30 19:24   \n",
       "5           6  2018-09-30 19:23   \n",
       "6           7  2018-09-30 19:13   \n",
       "7           8  2018-09-30 19:09   \n",
       "8           9  2018-09-30 19:00   \n",
       "9          10  2018-09-30 19:00   \n",
       "\n",
       "                                              Tweets  uncleaned_len  \\\n",
       "0  growing food faith impoverished brazil ben dem...            247   \n",
       "1  yrs vietnam poverty emerging market ans oi moi...            429   \n",
       "2  politics poverty officials grapple works doesn...            309   \n",
       "3  talking kenyalendahand kenya nairobi kibera ja...            292   \n",
       "4                                    raiders poverty             25   \n",
       "5  believe world gone bonkers need evolve better ...            234   \n",
       "6  even breathing risk one orlando poorest neighb...            207   \n",
       "7  maybe time rethink idea know better people nee...            192   \n",
       "8  volunteer big bros big sisters many american k...            191   \n",
       "9  americas children brief key national indicator...            279   \n",
       "\n",
       "   cleaned_len                                          Tokensize  \n",
       "0           89  [growing, food, faith, impoverished, brazil, b...  \n",
       "1          220  [yrs, vietnam, poverty, emerging, market, ans,...  \n",
       "2           96  [politics, poverty, officials, grapple, works,...  \n",
       "3          166  [talking, kenyalendahand, kenya, nairobi, kibe...  \n",
       "4           17                                 [raiders, poverty]  \n",
       "5          212  [believe, world, gone, bonkers, need, evolve, ...  \n",
       "6          151  [even, breathing, risk, one, orlando, poorest,...  \n",
       "7          125  [maybe, time, rethink, idea, know, better, peo...  \n",
       "8          166  [volunteer, big, bros, big, sisters, many, ame...  \n",
       "9          211  [americas, children, brief, key, national, ind...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6 POS tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import pos_tag\n",
    "train['POS_TAG'] = train['Tokensize'].apply(lambda x: pos_tag(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweets</th>\n",
       "      <th>POS_TAG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>growing food faith impoverished brazil ben dem...</td>\n",
       "      <td>[(growing, VBG), (food, NN), (faith, NN), (imp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>yrs vietnam poverty emerging market ans oi moi...</td>\n",
       "      <td>[(yrs, NN), (vietnam, NNP), (poverty, NN), (em...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>politics poverty officials grapple works doesn...</td>\n",
       "      <td>[(politics, NNS), (poverty, NN), (officials, N...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>talking kenyalendahand kenya nairobi kibera ja...</td>\n",
       "      <td>[(talking, VBG), (kenyalendahand, NN), (kenya,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>raiders poverty</td>\n",
       "      <td>[(raiders, NNS), (poverty, VBP)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>believe world gone bonkers need evolve better ...</td>\n",
       "      <td>[(believe, JJ), (world, NN), (gone, VBN), (bon...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>even breathing risk one orlando poorest neighb...</td>\n",
       "      <td>[(even, RB), (breathing, VBG), (risk, NN), (on...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>maybe time rethink idea know better people nee...</td>\n",
       "      <td>[(maybe, RB), (time, NN), (rethink, VB), (idea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>volunteer big bros big sisters many american k...</td>\n",
       "      <td>[(volunteer, NN), (big, JJ), (bros, NN), (big,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>americas children brief key national indicator...</td>\n",
       "      <td>[(americas, JJ), (children, NNS), (brief, JJ),...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Tweets  \\\n",
       "0  growing food faith impoverished brazil ben dem...   \n",
       "1  yrs vietnam poverty emerging market ans oi moi...   \n",
       "2  politics poverty officials grapple works doesn...   \n",
       "3  talking kenyalendahand kenya nairobi kibera ja...   \n",
       "4                                    raiders poverty   \n",
       "5  believe world gone bonkers need evolve better ...   \n",
       "6  even breathing risk one orlando poorest neighb...   \n",
       "7  maybe time rethink idea know better people nee...   \n",
       "8  volunteer big bros big sisters many american k...   \n",
       "9  americas children brief key national indicator...   \n",
       "\n",
       "                                             POS_TAG  \n",
       "0  [(growing, VBG), (food, NN), (faith, NN), (imp...  \n",
       "1  [(yrs, NN), (vietnam, NNP), (poverty, NN), (em...  \n",
       "2  [(politics, NNS), (poverty, NN), (officials, N...  \n",
       "3  [(talking, VBG), (kenyalendahand, NN), (kenya,...  \n",
       "4                   [(raiders, NNS), (poverty, VBP)]  \n",
       "5  [(believe, JJ), (world, NN), (gone, VBN), (bon...  \n",
       "6  [(even, RB), (breathing, VBG), (risk, NN), (on...  \n",
       "7  [(maybe, RB), (time, NN), (rethink, VB), (idea...  \n",
       "8  [(volunteer, NN), (big, JJ), (bros, NN), (big,...  \n",
       "9  [(americas, JJ), (children, NNS), (brief, JJ),...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[['Tweets', 'POS_TAG']].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6 Lemmetization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://github.com/KT12/tag-lemmatize/blob/master/tag-lemmatize.py\n",
    "\n",
    "#penn to wordnet, takes care of only 5 POS, rest converted to noun \n",
    "\n",
    "part = {\n",
    "    'N' : 'n',\n",
    "    'V' : 'v',\n",
    "    'J' : 'a',\n",
    "    'S' : 's',\n",
    "    'R' : 'r'\n",
    "}\n",
    "\n",
    "def convert_tag(penn_tag):\n",
    "    '''\n",
    "    convert_tag() accepts the **first letter** of a Penn part-of-speech tag,\n",
    "    then uses a dict lookup to convert it to the appropriate WordNet tag.\n",
    "    '''\n",
    "    if penn_tag in part.keys():\n",
    "        return part[penn_tag]\n",
    "    else:\n",
    "        # other parts of speech will be tagged as nouns\n",
    "        return 'n'\n",
    "    \n",
    "\n",
    "def tag_and_lem():\n",
    "    '''\n",
    "    tag_and_lem() accepts a string, tokenizes, tags, converts tags,\n",
    "    lemmatizes, and returns a string\n",
    "    '''\n",
    "    \"\"\n",
    "    \n",
    "\n",
    "    \n",
    "    lemm = []\n",
    "    i = 0\n",
    "    #sent = pos_tag(word_tokenize(element)) # must tag in context\n",
    "    for tweet in train.POS_TAG:\n",
    "        lemm = []\n",
    "        for words in tweet:\n",
    "            text = words[0]\n",
    "            tag = words[1]\n",
    "            lemm.append(\"\".join(lemmatiser.lemmatize(text, pos = convert_tag(tag))))\n",
    "        train.at[i, \"Lemmas\"] = lemm\n",
    "        i+= 1\n",
    "\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "train.insert(train.shape[1], 'Lemmas', '0')   #use this to create a default column \n",
    "lemmatiser = WordNetLemmatizer()\n",
    "tag_and_lem()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7 Display the Tweets after Performing NLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Date</th>\n",
       "      <th>Tweets</th>\n",
       "      <th>uncleaned_len</th>\n",
       "      <th>cleaned_len</th>\n",
       "      <th>Tokensize</th>\n",
       "      <th>POS_TAG</th>\n",
       "      <th>Lemmas</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2018-09-30 19:39</td>\n",
       "      <td>growing food faith impoverished brazil ben dem...</td>\n",
       "      <td>247</td>\n",
       "      <td>89</td>\n",
       "      <td>[growing, food, faith, impoverished, brazil, b...</td>\n",
       "      <td>[(growing, VBG), (food, NN), (faith, NN), (imp...</td>\n",
       "      <td>[growing, food, faith, impoverished, brazil, b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2018-09-30 19:37</td>\n",
       "      <td>yrs vietnam poverty emerging market ans oi moi...</td>\n",
       "      <td>429</td>\n",
       "      <td>220</td>\n",
       "      <td>[yrs, vietnam, poverty, emerging, market, ans,...</td>\n",
       "      <td>[(yrs, NN), (vietnam, NNP), (poverty, NN), (em...</td>\n",
       "      <td>[yr, vietnam, poverty, emerging, market, an, o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2018-09-30 19:37</td>\n",
       "      <td>politics poverty officials grapple works doesn...</td>\n",
       "      <td>309</td>\n",
       "      <td>96</td>\n",
       "      <td>[politics, poverty, officials, grapple, works,...</td>\n",
       "      <td>[(politics, NNS), (poverty, NN), (officials, N...</td>\n",
       "      <td>[politics, poverty, official, grapple, work, d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2018-09-30 19:29</td>\n",
       "      <td>talking kenyalendahand kenya nairobi kibera ja...</td>\n",
       "      <td>292</td>\n",
       "      <td>166</td>\n",
       "      <td>[talking, kenyalendahand, kenya, nairobi, kibe...</td>\n",
       "      <td>[(talking, VBG), (kenyalendahand, NN), (kenya,...</td>\n",
       "      <td>[talking, kenyalendahand, kenya, nairobi, kibe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2018-09-30 19:24</td>\n",
       "      <td>raiders poverty</td>\n",
       "      <td>25</td>\n",
       "      <td>17</td>\n",
       "      <td>[raiders, poverty]</td>\n",
       "      <td>[(raiders, NNS), (poverty, VBP)]</td>\n",
       "      <td>[raider, poverty]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0              Date  \\\n",
       "0           1  2018-09-30 19:39   \n",
       "1           2  2018-09-30 19:37   \n",
       "2           3  2018-09-30 19:37   \n",
       "3           4  2018-09-30 19:29   \n",
       "4           5  2018-09-30 19:24   \n",
       "\n",
       "                                              Tweets  uncleaned_len  \\\n",
       "0  growing food faith impoverished brazil ben dem...            247   \n",
       "1  yrs vietnam poverty emerging market ans oi moi...            429   \n",
       "2  politics poverty officials grapple works doesn...            309   \n",
       "3  talking kenyalendahand kenya nairobi kibera ja...            292   \n",
       "4                                    raiders poverty             25   \n",
       "\n",
       "   cleaned_len                                          Tokensize  \\\n",
       "0           89  [growing, food, faith, impoverished, brazil, b...   \n",
       "1          220  [yrs, vietnam, poverty, emerging, market, ans,...   \n",
       "2           96  [politics, poverty, officials, grapple, works,...   \n",
       "3          166  [talking, kenyalendahand, kenya, nairobi, kibe...   \n",
       "4           17                                 [raiders, poverty]   \n",
       "\n",
       "                                             POS_TAG  \\\n",
       "0  [(growing, VBG), (food, NN), (faith, NN), (imp...   \n",
       "1  [(yrs, NN), (vietnam, NNP), (poverty, NN), (em...   \n",
       "2  [(politics, NNS), (poverty, NN), (officials, N...   \n",
       "3  [(talking, VBG), (kenyalendahand, NN), (kenya,...   \n",
       "4                   [(raiders, NNS), (poverty, VBP)]   \n",
       "\n",
       "                                              Lemmas  \n",
       "0  [growing, food, faith, impoverished, brazil, b...  \n",
       "1  [yr, vietnam, poverty, emerging, market, an, o...  \n",
       "2  [politics, poverty, official, grapple, work, d...  \n",
       "3  [talking, kenyalendahand, kenya, nairobi, kibe...  \n",
       "4                                  [raider, poverty]  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8 Sentimental Analysis using VADER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyser = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sentimental analysis based on compund score of VADER\n",
    "sentiment = []\n",
    "i= 0 \n",
    "for tweet in train.Tweets:\n",
    "    vs = analyser.polarity_scores(tweet)\n",
    "    if vs['compound'] >= 0.5:\n",
    "        sentiment.append(1)\n",
    "    elif vs['compound'] <= -0.5:\n",
    "        sentiment.append(-1)\n",
    "    elif vs['compound'] > - 0.5 and vs['compound'] < 0.5:\n",
    "        sentiment.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "newtrain = pd.DataFrame(columns = ['Date', 'Review', 'Sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a new dataframe for storing sentiments values\n",
    "newtrain['Date'] = train.Date\n",
    "newtrain['Review'] = train.Tweets\n",
    "newtrain['Sentiment'] = sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Review</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-09-30 19:39</td>\n",
       "      <td>growing food faith impoverished brazil ben dem...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-09-30 19:37</td>\n",
       "      <td>yrs vietnam poverty emerging market ans oi moi...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-09-30 19:37</td>\n",
       "      <td>politics poverty officials grapple works doesn...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-09-30 19:29</td>\n",
       "      <td>talking kenyalendahand kenya nairobi kibera ja...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-09-30 19:24</td>\n",
       "      <td>raiders poverty</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2018-09-30 19:23</td>\n",
       "      <td>believe world gone bonkers need evolve better ...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2018-09-30 19:13</td>\n",
       "      <td>even breathing risk one orlando poorest neighb...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2018-09-30 19:09</td>\n",
       "      <td>maybe time rethink idea know better people nee...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2018-09-30 19:00</td>\n",
       "      <td>volunteer big bros big sisters many american k...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2018-09-30 19:00</td>\n",
       "      <td>americas children brief key national indicator...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Date                                             Review  \\\n",
       "0  2018-09-30 19:39  growing food faith impoverished brazil ben dem...   \n",
       "1  2018-09-30 19:37  yrs vietnam poverty emerging market ans oi moi...   \n",
       "2  2018-09-30 19:37  politics poverty officials grapple works doesn...   \n",
       "3  2018-09-30 19:29  talking kenyalendahand kenya nairobi kibera ja...   \n",
       "4  2018-09-30 19:24                                    raiders poverty   \n",
       "5  2018-09-30 19:23  believe world gone bonkers need evolve better ...   \n",
       "6  2018-09-30 19:13  even breathing risk one orlando poorest neighb...   \n",
       "7  2018-09-30 19:09  maybe time rethink idea know better people nee...   \n",
       "8  2018-09-30 19:00  volunteer big bros big sisters many american k...   \n",
       "9  2018-09-30 19:00  americas children brief key national indicator...   \n",
       "\n",
       "   Sentiment  \n",
       "0          0  \n",
       "1         -1  \n",
       "2         -1  \n",
       "3         -1  \n",
       "4         -1  \n",
       "5         -1  \n",
       "6         -1  \n",
       "7          0  \n",
       "8         -1  \n",
       "9          1  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dataset after sentimental analysis\n",
    "newtrain.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9 Convert the timestampColumn to proper format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "from dateutil.parser import parse\n",
    "\n",
    "newtrain['Date'] = pd.to_datetime(newtrain.Date, dayfirst=True)  #Y/M/D default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write the classified data to csv file\n",
    "newtrain.to_csv(\"Sentiment_Twitter_Poverty.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
